{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop: Deep Learning for Image Processing\n",
    "\n",
    "The objective of this workshop is to introduce the basic concepts of deep learning for image processing. We will use the [Keras](https://keras.io/) library to build and train a convolutional neural network for image classification.\n",
    "\n",
    "For people which use python 1.12 in local, you can use venv or conda to create a virtual environment with python 3.11 to run this workshop. Otherwise, you can use [Google Colab](https://colab.research.google.com/) to run the notebook.\n",
    "\n",
    "In this workshop, we will use first use the [MINST](https://keras.io/api/datasets/mnist/) dataset to train a model to recognize handwritten digits. Then, we will use the [CIFAR-10](https://keras.io/api/datasets/cifar10/) dataset to train a model to recognize objects in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Load the MINST dataset\n",
    "\n",
    "The MINST dataset contains 70,000 images of handwritten digits. Each image is a 28x28 grayscale image. The dataset is split into 60,000 training images and 10,000 test images.\n",
    "\n",
    "For this exercise, we will load the dataset and plot the first 25 images of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: One-hot encode the labels \n",
    "\n",
    "The labels of the MINST dataset are integers between 0 and 9. For this exercise, we will one-hot encode the labels. For example, the label 3 will be encoded as [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Build a convolutional neural network\n",
    "\n",
    "For this exercise, we will build a convolutional neural network to classify the images of the MINST dataset. The network will be made of 5 different types of layers:\n",
    "- *convolutional layers*: a convolutional layer convolves the input with a set of filters, each producing one feature map in the output. The convolutional layer is followed by an activation function.\n",
    "- *pooling layers*: pooling layers downsample the input along the spatial dimensions (width, height) by taking the maximum, average, etc. of a subset of the input.\n",
    "- *flatten layers*: flatten the input\n",
    "- *Dropout layers*: randomly set a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting.\n",
    "- *dense layers*: fully connected layers\n",
    "\n",
    "For each layer, an activation function is applied to the output of the layer. The activation function is a non-linear function that is applied to the output of a layer. It allows the network to learn complex patterns in the data. For this exercise, we will use the [ReLU](https://keras.io/api/layers/activations/#relu-function) activation function.\n",
    "\n",
    "> For the last layer, we will use the [softmax](https://keras.io/api/layers/activations/#softmax-function) activation function. The softmax function is a generalization of the sigmoid function to multiple dimensions. It is often used as the activation function for the last layer of a classification network. It takes as input a vector of real numbers and normalizes it into a probability distribution consisting of non-negative real numbers that sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4: Compile the model\n",
    "\n",
    "For this exercise, we will compile the model. In order to do so, we need to specify the loss function and the optimizer. The [loss function](https://keras.io/api/losses/) is a function that measures the difference between the predicted value of the network and the true value. The [optimizer](https://keras.io/api/optimizers/) is an algorithm that will update the parameters of the network in order to minimize the loss function.\n",
    "\n",
    "Also display the summary of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5: Train the model\n",
    "\n",
    "For this exercise, we will train the model. We will use the [fit](https://keras.io/api/models/model_training_apis/#fit-method) method of the model to train the model. The fit method trains the model for a fixed number of epochs (iterations on a dataset). For each epoch, it first shuffles the training data, then proceeds to the training of each batch. At the end of each epoch, the validation data is used to evaluate the model.\n",
    "\n",
    "> For this exercise we will use only the first 1000 images for training set in order to speed up the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6: Plot the training accuracy and validation loss\n",
    "\n",
    "For this exercise, we will plot the training accuracy and validation loss. We will use the [history](https://keras.io/api/models/model_training_apis/#fit-method) attribute of the model to get the training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7: Evaluate the model\n",
    "\n",
    "For this exercise, we will evaluate the model on the test set. We will use the [evaluate](https://keras.io/api/models/model_training_apis/#evaluate-method) method of the model to evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8: Harder case: CIFAR-10\n",
    "\n",
    "Previously, we used the MINST dataset to train a model to recognize handwritten digits. But this dataset is too simple to evaluate the performance of a model. For this exercise, we will use the CIFAR-10 dataset to train a model to recognize objects in images. The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes. The dataset is split into 50,000 training images and 10,000 test images.\n",
    "\n",
    "Your objective is to build a convolutional neural network to classify the images of the CIFAR-10 dataset. You can use everything you learned in the previous exercises, but you will need to adapt the model to work with color images and the image of the CIFAR-10 dataset. But you need to optimize your architecture to get the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this workshop, you have implemented a simple convolutional neural network to classify images, and you have learned how to use the Keras library to build and train a convolutional neural network. But you can go further and try to implement a more complex convolutional neural network to solve more realistics problems.\n",
    "\n",
    "# To go further\n",
    "\n",
    "To go further, you can try to implement a more complex convolutional neural network to solve more realistics problems or difficult problems, such as Ciphar-100. You can also try to use alternative libraries, such as [PyTorch](https://pytorch.org/) or [TensorFlow](https://www.tensorflow.org/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
