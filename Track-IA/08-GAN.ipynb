{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop: Generative Adversarial Networks\n",
    "\n",
    "In this workshop, we will implement a Generative Adversarial Network (GAN) to generate images of handwritten digits. We will use the MNIST dataset, which contains 70,000 images of handwritten digits. Each image is a 28x28 grayscale image, and each pixel has a value between 0 and 255.\n",
    "\n",
    "The GAN will consist of two neural networks: a generator and a discriminator. The generator will take a random vector as input and output an image. The discriminator will take an image as input and output a probability that the image is real (as opposed to generated). The two networks will be trained together, with the goal of the generator producing images that are indistinguishable from real images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Preparing the data\n",
    "\n",
    "In order to train the GAN, we need to prepare the data. We will use the MNIST dataset, which is available in the `keras.datasets` module. The dataset is split into a training set and a test set, but we will only use the X from the training set.\n",
    "\n",
    "We will create a function that will load the dataset, normalize the pixel values to be between -1 and 1, and also reshape the images to be 28x28x1 instead of 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Creating the generator\n",
    "\n",
    "The generator will take a random vector (called: noise) as input and output an image, in order to ensure that the generator is able to produce different images.\n",
    "\n",
    "For the generator, we will use a neural network with 3 layers.\n",
    "- The first layer will be a dense layer with 256 neurons, a Leaky ReLU activation function with an alpha of 0.2 and a batch normalization layer with a momentum of 0.8.\n",
    "- The second layer will be a dense layer with 512 neurons, a Leaky ReLU activation function with an alpha of 0.2 and a batch normalization layer with a momentum of 0.8.\n",
    "- The third layer will be a dense layer with 1024 neurons, a Leaky ReLU activation function with an alpha of 0.2 and a batch normalization layer with a momentum of 0.8.\n",
    "- The fourth layer will be a dense layer with the number of neurons equal to the number of pixels in the image (28x28), and a tanh activation function.\n",
    "\n",
    "After the fourth layer, we will reshape the output to be 28x28x1 (hint: use the Reshape layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Creating the discriminator\n",
    "\n",
    "The discriminator will take an image as input and output a probability that the image is real (as opposed to generated).\n",
    "\n",
    "For the discriminator, we will use a neural network with 3 layers.\n",
    "- The first layer will be a dense layer with 512 neurons, a Leaky ReLU activation function with an alpha of 0.2.\n",
    "- The second layer will be a dense layer with 256 neurons, a Leaky ReLU activation function with an alpha of 0.2.\n",
    "- The third layer will be a dense layer with 1 neuron, and a sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4: Displaying the images\n",
    "\n",
    "In order to see the images that the generator produces, we will create a function that will save a grid of images to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5: Creating the GAN\n",
    "\n",
    "Now that we have the generator and the discriminator, we can create the GAN. The GAN will consist of the generator and the discriminator, connected in a sequential manner. The discriminator will be frozen during training, so that only the generator will be trained.\n",
    "\n",
    "In order to train the GAN, we will use the Adam optimizer with a learning rate of 0.0002 and a momentum of 0.5. We will use binary crossentropy as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6: Training the GAN\n",
    "\n",
    "Now that we have the GAN, we need to create a function that will train the GAN.\n",
    "\n",
    "The training process will consist of multiple steps:\n",
    "1. we will select a random batch of images from the training set.\n",
    "2. we will generate a random batch of images using the generator.\n",
    "3. we will train the discriminator on the real images\n",
    "4. we will train the discriminator on the generated images\n",
    "5. We will calculate the loss for the discriminator\n",
    "6. We will train the Combined model (the GAN) with noise as input and ones as output\n",
    "7. We will save images to a file every 200 epochs\n",
    "\n",
    "\n",
    "> **Note:** The training process of a GAN is very long, so you will need a lot of epochs in order to get good results. We recommend 2000 epochs or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7: Generating images\n",
    "\n",
    "Now that we have trained the GAN, we can use the generator to generate images.\n",
    "\n",
    "We will create a function that will generate a random batch of images using the generator, and then save the images to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this workshop, we have implemented a Generative Adversarial Network (GAN) to generate images of handwritten digits. We have used the MNIST dataset, which contains 70,000 images of handwritten digits. Each image is a 28x28 grayscale image, and each pixel has a value between 0 and 255.\n",
    "\n",
    "# To go further\n",
    "\n",
    "To go further, now that you know how to implement a GAN, you can try to implement a GAN to generate images of faces. You can use the CelebA dataset, which contains 202,599 images of faces. Each image is a 178x218 RGB image, and each pixel has a value between 0 and 255. Otherwise, you can try to implement diffent types of GANs, such as a Conditional GAN (CGAN) or a Deep Convolutional GAN (DCGAN)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
